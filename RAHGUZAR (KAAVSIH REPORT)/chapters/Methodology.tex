
The methodology for Rahguzar was designed as a structured, research-driven response to the operational inefficiencies in manual Permanent Journey Plan (PJP) scheduling. The project aimed to generate optimized PJPs that adhered to real-world constraints in the FMCG distribution landscape of Pakistan. Given the scale and complexity of the problem, we adopted a modular and algorithmically hybrid approach, structured into three main phases: Clustering, Scheduling, and Route Optimization.

Our methodology combined custom algorithm development with empirical evaluation on real-world datasets. This allowed us to balance theoretical rigor with practical usability, ensuring that the final solution could be deployed under real operational conditions.


\section{Problem Formulation}

The PJP problem is modeled as a weekly, constraint-aware variation of the VRPTW. Given a set of stores with known coordinates, visit frequencies, service durations, and territory assignments, the objective is to generate an optimized journey plan for each order booker such that:

\begin{itemize}
  \item Store visits satisfy required weekly frequencies
  \item Visits are spaced evenly across working days
  \item Total route time (travel + service) per day remains within shift limits (typically 8 hours)
  \item Order booker workload is balanced across the team
  \item Routes are geographically compact and operationally realistic
\end{itemize}

Due to the NP-hard nature of the problem, exact optimization methods are impractical in a real world setting. Instead, we use a hybrid, heuristic-based approach structured into three phases.

\section{Three-Phase Algorithmic Architecture}

\subsection{Clustering}

The clustering phase assigns stores to order bookers through a hybrid clustering pipeline that balances geographic proximity with workload equity. This process allows the system to divide a large set of stores into manageable groups, which can then be assigned to specific order bookers in a logical and efficient manner.

\textbf{Graph-Based Clustering.} A Minimum Spanning Tree (MST) is constructed using store location data. The MST connects all stores with the minimal possible total edge weight, ensuring that geographically close stores are grouped together with minimal travel distance. This forms the initial clusters that are further refined in the next steps.

\textbf{K-Means Refinement.} Each graph-based cluster is refined by minimizing the internal variance within the cluster using the K-means algorithm. The centroid $C_i$ of each cluster is recalculated using:

\[
C_i = \frac{1}{N_i} \sum_{x \in S_i} x
\]

\textbf{where:}
\begin{itemize}
  \item $C_i$: The new centroid of cluster $i$
  \item $N_i$: The number of stores in cluster $i$
  \item $x \in S_i$: The coordinates of each store $x$ in cluster $S_i$
\end{itemize}
% Where: 
% Where: \\
% $C_i$: The new centroid of cluster $i$ \\
% $N_i$: The number of stores in cluster $i$ \\
% $x \in S_i$: The coordinates of each store $x$ in cluster $S_i$

\textbf{Outlier Reassignment.} After initial refinement, stores that lie significantly far from their assigned cluster centroid are identified using:

\[
D_{s,c} > \mu + \sigma \cdot k
\]
\textbf{where:}
\begin{itemize}
  \item $D_{s,c}$: Distance of store $s$ from the centroid of its assigned cluster $c$ 
  \item $\mu$: Mean distance of all stores in the cluster from the centroid
  \item $\sigma$: Standard deviation of the distances
  \item $k$: Scaling factor used for thresholding
\end{itemize}

% Where: \\
% $D_{s,c}$: Distance of store $s$ from the centroid of its assigned cluster $c$ \\
% $\mu$: Mean distance of all stores in the cluster from the centroid \\
% $\sigma$: Standard deviation of the distances \\
% $k$: Scaling factor used for thresholding

Such outliers are then reassigned to the nearest neighboring cluster. This improves overall cluster consistency and prevents inefficiencies in route planning due to geographical anomalies.

\textbf{Workload Balancing.} To ensure equitable distribution of stores across order bookers, workloads are balanced by minimizing the squared workload error:

\[
SSE = \sum_{c}(W_c - \bar{W})^2
\]

\textbf{where:}
\begin{itemize}
  \item $W_c$: Total workload of cluster $c$ 
  \item $\bar{W}$: Average workload across all clusters
\end{itemize}
% Where: 
% \\
% $W_c$: Total workload of cluster $c$ \\
% $\bar{W}$: Average workload across all clusters

This multi-step clustering strategy ensures both spatial efficiency and fair workload distribution across field staff. The use of MST helps with initial proximity grouping, K-means ensures tight clusters, outlier reassignment handles anomalies, and workload balancing ensures equity. Together, they set a strong foundation for downstream scheduling and routing.

\subsection{Scheduling}

After clustering, each order booker’s list of stores is scheduled across the working week using a custom Evolutionary Algorithm (EA). This approach is designed to distribute store visits over time in a way that balances efficiency with business constraints.

\textbf{Population Initialization.} Initial schedules are generated randomly and based on geographic heuristics. This combination provides enough diversity for the EA to explore a wide range of configurations and forms the basis for iterative improvements.

\textbf{Fitness Evaluation.} Each schedule is evaluated using the following fitness function:

\[
F = T_{\text{total}} + P_{\text{mismatch}} + P_{\text{imbalance}} + P_{\text{geo}}
\]

\textbf{where:}
\begin{itemize}
  \item $T_{\text{total}}$: Total time taken for travel and service across all days
  \item $P_{\text{mismatch}}$: Penalty for not meeting store visit frequency
  \item $P_{\text{imbalance}}$: Penalty for workload imbalance across order bookers
  \item $P_{\text{geo}}$: Penalty for geographical inefficiencies in route shape
\end{itemize}
This function balances multiple scheduling objectives. A lower score indicates a more optimal schedule under all constraints.

\textbf{Constraints.} Daily work limits are enforced using:

\[
T_{\text{day}} = \sum_{i=1}^{n} T_{\text{travel},i} + \sum_{i=1}^{n} T_{\text{service},i} \leq 480
\]

\textbf{where:}
\begin{itemize}
  \item $T_{\text{travel},i}$: Travel time to store $i$
  \item $T_{\text{service},i}$: Service time at store $i$
  \item $n$: Number of stores in the daily route
\end{itemize}
This ensures feasibility within an 8-hour workday and aligns schedules with operational constraints.

Crossover and mutation operations are applied to refine the population of schedules over successive generations. Tournament selection is used to identify high-performing candidates, from which crossover generates new schedules by combining elements of the best solutions. Mutation then introduces small random changes to maintain diversity in the population and prevent premature convergence to local optima. Together, these mechanisms drive the evolutionary algorithm toward more optimal and robust scheduling outcomes.

\subsection{Route Optimization}

Once a feasible schedule is generated during Phase 2, each day's assigned store list undergoes route optimization to minimize travel time and ensure compliance with daily constraints. This process uses a two-step strategy, with the Nearest Neighbor (NN) heuristic integrated into the scheduling phase and the OR-Tools Traveling Salesman Problem (TSP) solver applied afterward for refinement.

\textbf{Step 1: Nearest Neighbor (NN) during Scheduling.} During the evolutionary algorithm-based scheduling process, the NN heuristic is used to estimate daily route times. This involves constructing a route starting from the depot and iteratively visiting the nearest unvisited store. It serves as a fast, low-cost approximation to guide constraint checking (e.g., total duration under 480 minutes) and fitness evaluation during schedule generation.

\textbf{Step 2: OR-Tools TSP Solver Post-Scheduling.} After scheduling is complete, each daily route is passed to the OR-Tools TSP Solver for optimization. This solver refines the visiting sequence to minimize total tour length:

\[
\min \sum_{i=1}^{r-1} D_{i,i+1} + D_{r,1}
\]

\textbf{where:}
\begin{itemize}
  \item $r$: Total number of stores in the daily route
  \item $D_{i,i+1}$: Distance between consecutive stores $i$ and $i+1$
  \item $D_{r,1}$: Distance from the final store back to the depot
\end{itemize}

Thus, the routes are constrained to a maximum daily duration of 480 minutes. This two-step method combines the speed of Nearest Neighbor with the precision of OR-Tools, ensuring route quality, feasibility, and scalability for FMCG operations.
\section{Data Preprocessing Strategy}

% The input datasets were provided by SalesFlo in Excel format. The preprocessing pipeline involved:

% \begin{itemize}
%   \item Parsing and cleaning using Python
%   \item Merging datasets by unique store identifiers
%   \item Migrating structured data into a PostgreSQL database
%   \item Filtering stores by operational zones for the pilot phase
% \end{itemize}

% This ensured consistency and readiness for integration into the optimization pipeline.
The input datasets, provided by SalesFlo in Excel format, were preprocessed using a structured pipeline to ensure data quality and consistency. Parsing and cleaning were performed using Python, followed by merging multiple files based on unique store identifiers. The cleaned and integrated data was then migrated into a PostgreSQL database to enable efficient querying and relational operations. For the pilot implementation, stores were filtered by predefined operational zones to restrict testing to relevant geographic clusters. This preprocessing ensured that the data was normalized, reliable, and ready for direct integration into the clustering, scheduling, and routing optimization pipeline.
% \section{Assumptions}
% To simplify computation and focus on core scheduling and routing challenges, several assumptions were applied throughout the system design. Travel times were treated as static averages, without modeling real-time traffic conditions. All routes were assumed to start and end at a fixed distributor location. Store service durations were considered known and constant across the planning horizon. Additionally, planning was conducted on a weekly basis, excluding Sundays, to align with standard operational cycles. These assumptions allowed the algorithmic components to remain tractable while preserving alignment with real-world FMCG workflows.
% % To maintain focus and computational tractability, the following assumptions were made:

% \begin{itemize}
%   \item Static average travel times are used; live traffic is not modeled
%   \item Each route begins and ends at a fixed distributor
%   \item Store service durations are known and fixed
%   \item Planning is performed on a weekly horizon excluding Sundays
% \end{itemize}

\section{Algorithmic Complexity}

Rahguzar’s modular pipeline breaks the PJP problem into three heuristically optimized stages: clustering, scheduling, and routing. While the overall problem is NP-hard, each component is designed to ensure scalability through local heuristics and bounded iterations.

\begin{itemize}
  \item \textbf{Clustering:} Graph-based clustering is performed using pairwise haversine distances with complexity $O(n^2)$, followed by K-Means refinement ($O(nki)$) and outlier reassignment ($O(n)$). This phase is executed once and scales well for realistic values of $n$ (number of stores) and $k$ (number of order bookers).

  \item \textbf{Scheduling (EA):} The Evolutionary Algorithm runs for $G_{EA}$ generations (typically 80–100) with a population size $P$ (typically 40–50). Fitness evaluation includes total route time, visit frequency matching, and workload balancing. Complexity per generation is $O(P \cdot n)$, giving:
  \[
  O(P \cdot n \cdot G_{EA})
  \]

  \item \textbf{Routing (Nearest Neighbor + OR-Tools):} For each day, an initial path is constructed using the Nearest Neighbor (NN) heuristic. This is followed by route refinement using Google's OR-Tools TSP solver, which minimizes the total travel distance:
\[
\min \sum_{i=1}^{r-1} D_{i,i+1} + D_{r,1}
\]
For $r$ stores per route across $d$ daily routes, the empirical time complexity is approximately:
\[
O(d \cdot r^2)
\]
This two-step routing ensures scalable and high-quality solutions for daily planning under operational constraints.
\end{itemize}

\textbf{Total System Complexity:}

Combining the three stages, the total time complexity of Rahguzar’s algorithm is:

\[
O(n^2 + nk + P \cdot n \cdot G_{EA} + d \cdot r^2)
\]


This formulation reflects both theoretical bounds and empirical performance. In practice, early stopping, parallelism, and per-cluster decomposition significantly reduce runtime. Rahguzar consistently generated optimized plans for hundreds of stores in under 5 minutes on a standard multi-core machine.
